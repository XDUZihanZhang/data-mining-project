{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Data Splitting\n",
    "\n",
    "This notebook:\n",
    "- Loads the cleaned dataset\n",
    "- Splits it into training, validation, and test sets (70/15/15)\n",
    "- Stratifies the splits to maintain target class distribution\n",
    "- Saves the split datasets into `data/processed/` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of cleaned dataset: (991346, 24)\n",
      "\n",
      "Feature matrix X shape: (991346, 23)\n",
      "Target vector y shape: (991346,)\n",
      "\n",
      "Train set shape: (693942, 23) (693942,)\n",
      "Validation set shape: (148702, 23) (148702,)\n",
      "Test set shape: (148702, 23) (148702,)\n",
      "\n",
      "Datasets saved successfully to 'data/processed/' directory.\n"
     ]
    }
   ],
   "source": [
    "# 02_data_split.ipynb\n",
    "\n",
    "# ====================================================\n",
    "# 02. Data Splitting\n",
    "# ----------------------------------------------------\n",
    "# Objective:\n",
    "# - Load the cleaned dataset using a relative path\n",
    "# - Split the dataset into training, validation, and test sets\n",
    "# - Save the split datasets into the processed data directory\n",
    "# ====================================================\n",
    "\n",
    "## 1. Import necessary libraries\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## 2. Define relative file paths\n",
    "CLEANED_DATA_PATH = Path('../data/interim/alcohol_consumption_cleaned.csv')  # Cleaned input\n",
    "PROCESSED_TRAIN_PATH = Path('../data/processed/train.csv')\n",
    "PROCESSED_VAL_PATH = Path('../data/processed/val.csv')\n",
    "PROCESSED_TEST_PATH = Path('../data/processed/test.csv')\n",
    "\n",
    "## 3. Load the cleaned dataset\n",
    "df_cleaned = pd.read_csv(CLEANED_DATA_PATH)\n",
    "\n",
    "print(\"Shape of cleaned dataset:\", df_cleaned.shape)\n",
    "df_cleaned.head()\n",
    "\n",
    "## 4. Separate features (X) and target (y)\n",
    "# Assuming the target column is 'DRK_YN'\n",
    "TARGET_COLUMN = 'DRK_YN'\n",
    "X = df_cleaned.drop(columns=[TARGET_COLUMN])\n",
    "y = df_cleaned[TARGET_COLUMN]\n",
    "\n",
    "print(\"\\nFeature matrix X shape:\", X.shape)\n",
    "print(\"Target vector y shape:\", y.shape)\n",
    "\n",
    "## 5. Split the dataset: train (70%), val (15%), test (15%)\n",
    "# Step 1: Split train vs temp (val+test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.30, \n",
    "    stratify=y, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Split temp into val and test\n",
    "relative_val_size = 0.5  # Half of temp goes to validation, half to test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, \n",
    "    test_size=0.5, \n",
    "    stratify=y_temp, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "## 6. Verify the split ratios\n",
    "print(\"\\nTrain set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "## 7. Combine features and targets for saving\n",
    "train_set = pd.concat([X_train, y_train], axis=1)\n",
    "val_set = pd.concat([X_val, y_val], axis=1)\n",
    "test_set = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "## 8. Save the split datasets\n",
    "train_set.to_csv(PROCESSED_TRAIN_PATH, index=False)\n",
    "val_set.to_csv(PROCESSED_VAL_PATH, index=False)\n",
    "test_set.to_csv(PROCESSED_TEST_PATH, index=False)\n",
    "\n",
    "print(\"\\nDatasets saved successfully to 'data/processed/' directory.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
